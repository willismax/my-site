"use strict";(self.webpackChunkmy_site=self.webpackChunkmy_site||[]).push([[3461],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>f});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},m=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},_=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),u=p(n),_=r,f=u["".concat(l,".").concat(_)]||u[_]||d[_]||i;return n?a.createElement(f,o(o({ref:t},m),{},{components:n})):a.createElement(f,o({ref:t},m))}));function f(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=_;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:r,o[1]=s;for(var p=2;p<i;p++)o[p]=n[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}_.displayName="MDXCreateElement"},9716:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>p});var a=n(7462),r=(n(7294),n(3905));const i={jupyter:{jupytext:{text_representation:{extension:".md",format_name:"markdown",format_version:"1.3",jupytext_version:"1.15.1"}},kernelspec:{display_name:"Python 3",name:"python3"}}},o=void 0,s={unversionedId:"2021ITHome\u9435\u4eba\u8cfd\u300c\u5f9eAI\u843d\u5730\u8ac7MLOps\u300d/\u5be6\u4f5cNotebooks/TFX_\u7d44\u4ef6\u7b46\u8a18\u672c\u4e92\u52d5\u7bc4\u4f8b_\u9435\u4eba\u8cfd\u793a\u7bc4",id:"2021ITHome\u9435\u4eba\u8cfd\u300c\u5f9eAI\u843d\u5730\u8ac7MLOps\u300d/\u5be6\u4f5cNotebooks/TFX_\u7d44\u4ef6\u7b46\u8a18\u672c\u4e92\u52d5\u7bc4\u4f8b_\u9435\u4eba\u8cfd\u793a\u7bc4",title:"TFX_\u7d44\u4ef6\u7b46\u8a18\u672c\u4e92\u52d5\u7bc4\u4f8b_\u9435\u4eba\u8cfd\u793a\u7bc4",description:"- \u6b64\u70ba\u9435\u4eba\u5e6b\u7bc4\u4f8b\uff0c\u5167\u5bb9\u6e90\u81eaTFX\u5b98\u65b9\u7bc4\u4f8b\u3002",source:"@site/docs/2021ITHome\u9435\u4eba\u8cfd\u300c\u5f9eAI\u843d\u5730\u8ac7MLOps\u300d/\u5be6\u4f5cNotebooks/29.TFX_\u7d44\u4ef6\u7b46\u8a18\u672c\u4e92\u52d5\u7bc4\u4f8b_\u9435\u4eba\u8cfd\u793a\u7bc4.md",sourceDirName:"2021ITHome\u9435\u4eba\u8cfd\u300c\u5f9eAI\u843d\u5730\u8ac7MLOps\u300d/\u5be6\u4f5cNotebooks",slug:"/2021ITHome\u9435\u4eba\u8cfd\u300c\u5f9eAI\u843d\u5730\u8ac7MLOps\u300d/\u5be6\u4f5cNotebooks/TFX_\u7d44\u4ef6\u7b46\u8a18\u672c\u4e92\u52d5\u7bc4\u4f8b_\u9435\u4eba\u8cfd\u793a\u7bc4",permalink:"/my-site/docs/2021ITHome\u9435\u4eba\u8cfd\u300c\u5f9eAI\u843d\u5730\u8ac7MLOps\u300d/\u5be6\u4f5cNotebooks/TFX_\u7d44\u4ef6\u7b46\u8a18\u672c\u4e92\u52d5\u7bc4\u4f8b_\u9435\u4eba\u8cfd\u793a\u7bc4",draft:!1,editUrl:"https://github.com/willismax/my-site/blob/main/docs/2021ITHome\u9435\u4eba\u8cfd\u300c\u5f9eAI\u843d\u5730\u8ac7MLOps\u300d/\u5be6\u4f5cNotebooks/29.TFX_\u7d44\u4ef6\u7b46\u8a18\u672c\u4e92\u52d5\u7bc4\u4f8b_\u9435\u4eba\u8cfd\u793a\u7bc4.md",tags:[],version:"current",sidebarPosition:29,frontMatter:{jupyter:{jupytext:{text_representation:{extension:".md",format_name:"markdown",format_version:"1.3",jupytext_version:"1.15.1"}},kernelspec:{display_name:"Python 3",name:"python3"}}},sidebar:"tutorialSidebar",previous:{title:"TensorFlow_Serving_REST_API_\u9435\u4eba\u8cfd\u793a\u7bc4",permalink:"/my-site/docs/2021ITHome\u9435\u4eba\u8cfd\u300c\u5f9eAI\u843d\u5730\u8ac7MLOps\u300d/\u5be6\u4f5cNotebooks/TensorFlow_Serving_REST_API_\u9435\u4eba\u8cfd\u793a\u7bc4"},next:{title:"Docusaurus",permalink:"/my-site/docs/category/docusaurus"}},l={},p=[{value:"\u5b89\u88dd\u8207\u8a2d\u7f6e TFX \u74b0\u5883",id:"\u5b89\u88dd\u8207\u8a2d\u7f6e-tfx-\u74b0\u5883",level:2},{value:"\u5275\u5efa InteractiveContext",id:"\u5275\u5efa-interactivecontext",level:3},{value:"\u4e92\u52d5\u5f0f TFX components \u793a\u7bc4",id:"\u4e92\u52d5\u5f0f-tfx-components-\u793a\u7bc4",level:2},{value:"ExampleGen",id:"examplegen",level:3},{value:"StatisticsGen",id:"statisticsgen",level:3},{value:"SchemaGen",id:"schemagen",level:3},{value:"ExampleValidator",id:"examplevalidator",level:3},{value:"Transform",id:"transform",level:3},{value:"Trainer",id:"trainer",level:3},{value:"\u4f7f\u7528 TensorBoard \u5206\u6790\u8a13\u7df4",id:"\u4f7f\u7528-tensorboard-\u5206\u6790\u8a13\u7df4",level:3},{value:"Evaluator",id:"evaluator",level:3},{value:"Pusher",id:"pusher",level:3}],m={toc:p},u="wrapper";function d(e){let{components:t,...n}=e;return(0,r.kt)(u,(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("a",{href:"https://colab.research.google.com/github/willismax/ML-in-Production-30-days-sharing/blob/main/notebook/29.TFX_%E7%B5%84%E4%BB%B6%E7%AD%86%E8%A8%98%E6%9C%AC%E4%BA%92%E5%8B%95%E7%AF%84%E4%BE%8B_%E9%90%B5%E4%BA%BA%E8%B3%BD%E7%A4%BA%E7%AF%84.ipynb",target:"_parent"},(0,r.kt)("img",{src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open In Colab"})),(0,r.kt)("h1",{id:"29tfx-\u7d44\u4ef6\u7b46\u8a18\u672c\u4e92\u52d5\u5be6\u4f5c"},"29.TFX \u7d44\u4ef6\u7b46\u8a18\u672c\u4e92\u52d5\u5be6\u4f5c"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u6b64\u70ba\u9435\u4eba\u5e6b\u7bc4\u4f8b\uff0c\u5167\u5bb9\u6e90\u81ea",(0,r.kt)("a",{parentName:"li",href:"https://www.tensorflow.org/tfx/tutorials/tfx/components_keras"},"TFX\u5b98\u65b9\u7bc4\u4f8b"),"\u3002"),(0,r.kt)("li",{parentName:"ul"},"\u672c\u793a\u7bc4\u5c07\u4f7f\u7528 TensorFlow Extended (TFX) \u5404\u7d44\u4ef6\u5b8c\u6210\u6a5f\u68b0\u5b78\u7fd2\u7aef\u5c0d\u7aef\u4efb\u52d9\uff0c\u4e4b\u5f8c\u60a8\u4e5f\u53ef\u4ee5\u900f\u904e Apache Airflow \u53ca Apache Beam \u7de8\u6392\u3002"),(0,r.kt)("li",{parentName:"ul"},"ML\u4e2d\u7e7c\u8cc7\u6599 (ML Metadata) \u662f\u4fdd\u5b58 TFX \u5404\u7d44\u4ef6\u57f7\u884c\u6b77\u7a0b\u7684\u91cd\u8981\u8cc7\u6599\u5eab\uff0c\u6578\u64da\u53ef\u4fdd\u5b58\u5728 MySQL \u6216 SQLite \u8cc7\u6599\u5eab\uff0c\u5728 Colab \u793a\u7bc4\u6642\u662f\u66ab\u5b58\u5728 SQLite\u3002")),(0,r.kt)("h2",{id:"\u5b89\u88dd\u8207\u8a2d\u7f6e-tfx-\u74b0\u5883"},"\u5b89\u88dd\u8207\u8a2d\u7f6e TFX \u74b0\u5883"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="as4OTe2ukSqm"',id:'"as4OTe2ukSqm"'},"import sys\nif 'google.colab' in sys.modules:\n  !pip install --upgrade pip\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="S4SQA7Q5nej3"',id:'"S4SQA7Q5nej3"'},'!pip install -U tfx \n"\u8acb\u8a18\u5f97\u5b89\u88dd\u5b8c\u9700\u91cd\u65b0\u555f\u52d5\u57f7\u884c\u968e\u6bb5(Restart Runtime)\uff0c\u518d\u9032\u884c\u5f8c\u7e8c\u5167\u5bb9"\n')),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"\u5b89\u88dd\u5b8c\u9700\u91cd\u65b0\u555f\u52d5\u57f7\u884c\u968e\u6bb5(Restart Runtime)\uff0c\u518d\u9032\u884c\u5f8c\u7e8c\u5167\u5bb9")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="YIqpWK9efviJ"',id:'"YIqpWK9efviJ"'},"import os\nimport pprint\nimport tempfile\nimport urllib\n\nimport absl\nimport tensorflow as tf\nimport tensorflow_model_analysis as tfma\ntf.get_logger().propagate = False\npp = pprint.PrettyPrinter()\n\nfrom tfx import v1 as tfx\nfrom tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n\n%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip\n\nprint(f'TensorFlow version: {tf.__version__}') # >= 2.5.1\nprint(f'TFX version: {tfx.__version__}') # >= 1.2.0\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u8a2d\u5b9a Pipeline \u5de5\u4f5c\u8def\u5f91")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="ad5JLpKbf6sN"',id:'"ad5JLpKbf6sN"'},"# TFX \u6a21\u7d44\u5b89\u88dd\u539f\u59cb\u8def\u5f91_tfx_root\n_tfx_root = tfx.__path__[0]\n\n# \u829d\u52a0\u54e5\u8a08\u7a0b\u8eca\u8cc7\u6599\u96c6\u8def\u5f91_taxi_root\n_taxi_root = os.path.join(_tfx_root, 'examples/chicago_taxi_pipeline')\n\n# \u6a21\u578b\u767c\u5e03serving\u8def\u5f91_serving_model_dir\n_serving_model_dir = os.path.join(tempfile.mkdtemp(), 'serving_model/taxi_simple')\n\n# Set up logging.\nabsl.logging.set_verbosity(absl.logging.INFO)\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u4e0b\u8f09\u8cc7\u6599\u96c6\uff0c\u4ee5\u829d\u52a0\u54e5",(0,r.kt)("a",{parentName:"li",href:"https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew"},"Taxi Trips dataset")," \u9032\u884c\u793a\u7bc4\uff0c\u7279\u5fb5\u5982\u4e0b\uff0c\u5c07\u4f7f\u7528\u9019\u500b\u6578\u64da\u96c6\u69cb\u5efa\u4e00\u500b\u9810\u6e2c\u5c0f\u8cbb",(0,r.kt)("inlineCode",{parentName:"li"},"tips"),"\u7684\u6a21\u578b\u3002")),(0,r.kt)("table",null,(0,r.kt)("tr",null,(0,r.kt)("td",null,"pickup_community_area"),(0,r.kt)("td",null,"fare"),(0,r.kt)("td",null,"trip_start_month")),(0,r.kt)("tr",null,(0,r.kt)("td",null,"trip_start_hour"),(0,r.kt)("td",null,"trip_start_day"),(0,r.kt)("td",null,"trip_start_timestamp")),(0,r.kt)("tr",null,(0,r.kt)("td",null,"pickup_latitude"),(0,r.kt)("td",null,"pickup_longitude"),(0,r.kt)("td",null,"dropoff_latitude")),(0,r.kt)("tr",null,(0,r.kt)("td",null,"dropoff_longitude"),(0,r.kt)("td",null,"trip_miles"),(0,r.kt)("td",null,"pickup_census_tract")),(0,r.kt)("tr",null,(0,r.kt)("td",null,"dropoff_census_tract"),(0,r.kt)("td",null,"payment_type"),(0,r.kt)("td",null,"company")),(0,r.kt)("tr",null,(0,r.kt)("td",null,"trip_seconds"),(0,r.kt)("td",null,"dropoff_community_area"),(0,r.kt)("td",null,"tips"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="BywX6OUEhAqn"',id:'"BywX6OUEhAqn"'},"# \u5efa\u7acb/tmp/tfx-dataXXXXXXZ/\u6a94\u6848\u8def\u5f91_data_filepath\n_data_root = tempfile.mkdtemp(prefix='tfx-data')\nDATA_PATH = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/chicago_taxi_pipeline/data/simple/data.csv'\n_data_filepath = os.path.join(_data_root, \"data.csv\")\nurllib.request.urlretrieve(DATA_PATH, _data_filepath)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="c5YPeLPFOXaD"',id:'"c5YPeLPFOXaD"'},"# \u67e5\u770b\u8cc7\u6599\u96c6\u6a94\u6848\u78ba\u8a8d\u5167\u5bb9\n!head {_data_filepath}\n")),(0,r.kt)("h3",{id:"\u5275\u5efa-interactivecontext"},"\u5275\u5efa InteractiveContext"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"tfx.orchestration.experimental.interactive.interactive_context.InteractiveContext")," \u5141\u8a31\u5728 notebook \u74b0\u5883\u4e2d\u4ee5\u4e92\u52d5\u65b9\u5f0f\u67e5\u770b TFX \u7d44\u4ef6\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"InteractiveContext")," \u9810\u8a2d\u4f7f\u7528\u81e8\u6642\u7684\u4e2d\u7e7c\u8cc7\u6599\u3002",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\u5df2\u6709\u81ea\u5df1\u7684 pipeline \u53ef\u8a2d\u5b9a ",(0,r.kt)("inlineCode",{parentName:"li"},"pipe_root")," \u53c3\u6578\u3002"),(0,r.kt)("li",{parentName:"ul"},"\u5df2\u6709\u4e2d\u7e7c\u8cc7\u6599\u5eab\u53ef\u8a2d\u5b9a ",(0,r.kt)("inlineCode",{parentName:"li"},"metadata_connection_config")," \u53c3\u6578\u3002")))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="0Rh6K5sUf9dd"',id:'"0Rh6K5sUf9dd"'},"context = InteractiveContext()\n")),(0,r.kt)("h2",{id:"\u4e92\u52d5\u5f0f-tfx-components-\u793a\u7bc4"},"\u4e92\u52d5\u5f0f TFX components \u793a\u7bc4"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u672c\u7bc4\u4f8b\u5c07\u9010\u4e00\u793a\u7bc4\u5404\u7d44\u5efa\u7684\u5de5\u4f5c\uff0c\u4e5f\u900f\u904e ",(0,r.kt)("inlineCode",{parentName:"li"},"InteractiveContext()")," \u9010\u4e00\u6f14\u793a\u4e92\u52d5\u60c5\u5f62\u3002")),(0,r.kt)("h3",{id:"examplegen"},"ExampleGen"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"\u5c07\u6578\u64da\u62c6\u5206\u70ba\u8a13\u7df4\u96c6\u548c\u8a55\u4f30\u96c6\uff08\u9ed8\u8a8d\u60c5\u6cc1\u4e0b\uff0c2/3 \u8a13\u7df4 + 1/3 \u8a55\u4f30\uff09"),(0,r.kt)("li",{parentName:"ol"},"\u5c07\u6578\u64da\u8f49\u63db\u70ba ",(0,r.kt)("inlineCode",{parentName:"li"},"tf.Example")," \u683c\u5f0f\uff08\u53c3\u95b1",(0,r.kt)("a",{parentName:"li",href:"https://www.tensorflow.org/tutorials/load_data/tfrecord"},"\u8aaa\u660e"),"\uff09\u3002"),(0,r.kt)("li",{parentName:"ol"},"\u5c07\u6578\u64da\u8907\u88fd\u5230 ",(0,r.kt)("inlineCode",{parentName:"li"},"_tfx_root")," \u76ee\u9304\u4e2d\u4f9b\u5176\u4ed6\u7d44\u4ef6\u8a2a\u554f\u3002")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\u672c\u7bc4\u4f8b\u5c07 ",(0,r.kt)("inlineCode",{parentName:"p"},"_data_root")," \u7684 CSV \u8cc7\u6599\u96c6\u8f38\u5165\u81f3 ",(0,r.kt)("inlineCode",{parentName:"p"},"ExampleGen"),"\u3002")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\u6ce8\u610f\uff1a\u5728\u9019\u500b notebook \u793a\u7bc4\u4f7f\u7528",(0,r.kt)("inlineCode",{parentName:"p"},"InteractiveContext.run()"),"\u3002\u5728\u751f\u7522\u74b0\u5883\u4e2d\uff0c\u6703\u9810\u6307\u5b9a\u6240\u6709\u7d44\u4ef6",(0,r.kt)("inlineCode",{parentName:"p"},"Pipeline"),"\u4ee5\u50b3\u905e\u7d66\u5354\u8abf\u5668\uff08\u8acb\u53c3\u95b1",(0,r.kt)("a",{parentName:"p",href:"https://www.tensorflow.org/tfx/guide/build_tfx_pipeline"},"\u69cb\u5efa TFX \u7ba1\u9053\u6307\u5357"),"\uff09\u3002"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="PyXjuMt8f-9u"',id:'"PyXjuMt8f-9u"'},"example_gen = tfx.components.CsvExampleGen(input_base=_data_root)\ncontext.run(example_gen, enable_cache=True)\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"ExampleGen")," \u7d44\u4ef6\u5c07\u8f38\u51fa",(0,r.kt)("inlineCode",{parentName:"li"},"training examples")," \u3001 ",(0,r.kt)("inlineCode",{parentName:"li"},"evaluation examples")," \u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="880KkTAkPeUg"',id:'"880KkTAkPeUg"'},"artifact = example_gen.outputs['examples'].get()[0]\nprint(artifact.split_names, artifact.uri)\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u8f38\u51fa\u524d3\u7b46\u8cc7\u6599\u89c0\u5bdf")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="H4XIXjiCPwzQ"',id:'"H4XIXjiCPwzQ"'},"# Get the URI of the output artifact representing the training examples, which is a directory\ntrain_uri = os.path.join(\n    example_gen.outputs['examples'].get()[0].uri,\n    'Split-train'\n    )\n\n# Get the list of files in this directory (all compressed TFRecord files)\ntfrecord_filenames = [\n    os.path.join(train_uri, name) \n    for name in os.listdir(train_uri)\n    ]\n\n# Create a `TFRecordDataset` to read these files\ndataset = tf.data.TFRecordDataset(\n    tfrecord_filenames, \n    compression_type=\"GZIP\"\n    )\n\n# Iterate over the first 3 records and decode them.\nfor tfrecord in dataset.take(3):\n  serialized_example = tfrecord.numpy()\n  example = tf.train.Example()\n  example.ParseFromString(serialized_example)\n  pp.pprint(example)\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"ExampleGen")," \u5df2\u651d\u53d6\u8cc7\u6599\uff0c\u63a5\u7e8c\u8cc7\u6599\u5206\u6790\u3002")),(0,r.kt)("h3",{id:"statisticsgen"},"StatisticsGen"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"StatisticsGen")," \u7d44\u4ef6\u8f38\u5165 ",(0,r.kt)("inlineCode",{parentName:"li"},"ExampleGen")," \u6578\u64da\u5f8c\uff0c\u5c07\u64da\u4ee5\u8a08\u7b97\u51fa\u8cc7\u6599\u96c6\u7684\u7d71\u8a08\u6578\u64da\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"StatisticsGen")," \u662f ",(0,r.kt)("a",{parentName:"li",href:"https://www.tensorflow.org/tfx/data_validation/get_started"},"TFDV")," \u6a21\u7d44\u529f\u80fd\u4e4b\u4e00\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"context.run(statistics_gen)")," \u89c0\u5bdf\u4e92\u52d5\u4ecb\u9762\uff0c",(0,r.kt)("inlineCode",{parentName:"li"},".execution_id")," \u7248\u6b21\u7d2f\u52a0\u81f32\uff0c",(0,r.kt)("inlineCode",{parentName:"li"},".component.inputs")," \u7d44\u4ef6\u8f38\u5165\u70ba ",(0,r.kt)("inlineCode",{parentName:"li"},"Examples")," \uff0c \u8f38\u51fa\u70ba ",(0,r.kt)("inlineCode",{parentName:"li"},"ExampleStatistics")," \u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="MAscCCYWgA-9"',id:'"MAscCCYWgA-9"'},"statistics_gen = tfx.components.StatisticsGen(\n    examples=example_gen.outputs['examples'])\ncontext.run(statistics_gen, enable_cache=True)\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"context.show(statistics_gen.outputs['statistics'])")," \u5982\u540c TFDV \u5de5\u5177\u4ee5  ",(0,r.kt)("a",{parentName:"li",href:"https://pair-code.github.io/facets/"},"Facets")," \u8996\u89ba\u5316\u7d71\u8a08\u8cc7\u8a0a\u3002"),(0,r.kt)("li",{parentName:"ul"},"\u53ef\u4ee5\u89c0\u5bdf\u5224\u8b80\u53ef\u80fd\u7570\u5e38\u7684\u7d05\u8272\u503c\u3001\u8cc7\u6599\u5206\u4f48\u60c5\u5f62\u7b49\u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="tLjXy7K6Tp_G"',id:'"tLjXy7K6Tp_G"'},"context.show(statistics_gen.outputs['statistics'])\n")),(0,r.kt)("h3",{id:"schemagen"},"SchemaGen"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"SchemaGen"),"\u7d44\u4ef6\u6703\u4f9d\u64da\u60a8\u7684\u8cc7\u6599\u7d71\u8a08\u81ea\u52d5\u7522\u751f Schema \uff0c\u5305\u542b\u6578\u64da\u9810\u671f\u908a\u754c\u3001\u8cc7\u6599\u985e\u578b\u8207\u5c6c\u6027\u5b83\u9084\u4f7f\u7528",(0,r.kt)("a",{parentName:"li",href:"https://www.tensorflow.org/tfx/data_validation/get_started"},"TensorFlow \u6578\u64da\u9a57\u8b49"),"\u5eab\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"SchemaGen")," \u540c\u6a23\u662f ",(0,r.kt)("a",{parentName:"li",href:"https://www.tensorflow.org/tfx/data_validation/get_started"},"TFDV")," \u6a21\u7d44\u529f\u80fd\u4e4b\u4e00\u3002"),(0,r.kt)("li",{parentName:"ul"},"\u5373\u4fbf Schema \u81ea\u52d5\u751f\u6210\u5df2\u7d93\u5f88\u5be6\u7528\uff0c\u4f46\u60a8\u4ecd\u61c9\u8a72\u6703\u4f9d\u64da\u9700\u6c42\u9032\u884c\u5be9\u67e5\u548c\u4fee\u6539\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"SchemaGen")," \u8f38\u5165\u70ba ",(0,r.kt)("inlineCode",{parentName:"li"},"StatisticsGen"),"\uff0c\u9ed8\u8a8d\u60c5\u6cc1\u4e0b\u67e5\u770b\u5df2\u62c6\u5206\u7684\u8a13\u7df4\u8cc7\u6599\u96c6\u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="ygQvZ6hsiQ_J"',id:'"ygQvZ6hsiQ_J"'},"schema_gen = tfx.components.SchemaGen(\n    statistics=statistics_gen.outputs['statistics'],\n    infer_feature_shape=False)\ncontext.run(schema_gen, enable_cache=True)\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"SchemaGen")," \u57f7\u884c\u5f8c\u53ef\u900f\u904e ",(0,r.kt)("inlineCode",{parentName:"li"},"context.show(schema_gen.outputs['schema'])")," \u67e5\u770b  Schema \u8868\u683c\u3002"),(0,r.kt)("li",{parentName:"ul"},"\u8868\u683c\u5448\u73fe\u5404\u7279\u5fb5\u540d\u7a31\u3001\u5c6c\u6027\u3001\u662f\u5426\u5fc5\u9808\u3001\u6240\u6709\u503c\u3001Domain \u53ca \u908a\u754c\u7bc4\u570d\u7b49\uff0c\n\u53c3\u898b ",(0,r.kt)("a",{parentName:"li",href:"https://www.tensorflow.org/tfx/guide/schemagen"},"SchemaGen \u6587\u4ef6"),".\u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="Ec9vqDXpXeMb"',id:'"Ec9vqDXpXeMb"'},"context.show(schema_gen.outputs['schema'])\n")),(0,r.kt)("h3",{id:"examplevalidator"},"ExampleValidator"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"ExampleValidator")," \u7d44\u4ef6\u6839\u64da Schema \u7684\u9810\u671f\u6aa2\u6e2c\u6578\u64da\u4e2d\u7684\u7570\u5e38\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"ExampleValidator")," \u540c\u6a23\u662f ",(0,r.kt)("a",{parentName:"li",href:"https://www.tensorflow.org/tfx/data_validation/get_started"},"TFDV")," \u6a21\u7d44\u529f\u80fd\u4e4b\u4e00\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"ExampleValidator")," \u7684\u8f38\u5165\u662f\u4f86\u81ea\u5177\u6709\u6578\u64da\u7d71\u8a08\u8cc7\u8a0a\u7684 ",(0,r.kt)("inlineCode",{parentName:"li"},"StatisticsGen")," \u4ee5\u53ca\u5177\u6709\u6578\u64da\u5b9a\u7fa9 Schema \u7684 ",(0,r.kt)("inlineCode",{parentName:"li"},"SchemaGen"),"\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"ExampleValidator")," \u7684\u8f38\u51fa ",(0,r.kt)("inlineCode",{parentName:"li"},"anomalies")," \u662f\u6709\u7121\u7570\u5e38\u7684\u5224\u8b80\u7d50\u679c\u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="XRlRUuGgiXks"',id:'"XRlRUuGgiXks"'},"example_validator = tfx.components.ExampleValidator(\n    statistics=statistics_gen.outputs['statistics'],\n    schema=schema_gen.outputs['schema'])\ncontext.run(example_validator, enable_cache=True)\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u57f7\u884c ",(0,r.kt)("inlineCode",{parentName:"li"},"ExampleValidator")," \u5f8c\u53ef\u4ee5\u7522\u751f\u7570\u5e38\u60c5\u5f62\u7684\u5716\u8868\uff0c\u7da0\u5b57 No anomalies found. \u8868\u793a\u7121\u7570\u5e38\u3002"),(0,r.kt)("li",{parentName:"ul"},"\u7531\u65bc\u6b64\u70ba\u6700\u521d\u7684\u6578\u64da\u96c6\u8cc7\u8a0a\uff0c\u800c\u4e14\u7d71\u8a08\u8207 Schema \u7686\u662f\u7531\u8a72\u6578\u64da\u7522\u751f\uff0c\u7406\u61c9\u7121\u7570\u5e38\u3002\u672a\u4f86\u4e0d\u540c\u7248\u6b21\u7684\u8cc7\u8a0a\u6d41\u53ef\u80fd\u6703\u6aa2\u6e2c\u51fa\u7570\u5e38\u60c5\u5f62\u3002"),(0,r.kt)("li",{parentName:"ul"},"\u8cc7\u6599\u9a57\u8b49\u53ef\u7528 Schema \u4fdd\u8b77\u672a\u4f86\u6578\u64da\uff0c\u7570\u5e38\u5075\u6e2c\u53ef\u7528\u65bc\u8abf\u8a66\u6a21\u578b\u6027\u80fd\u3001\u4e86\u89e3\u6578\u64da\u5982\u4f55\u96a8\u6642\u9593\u6f14\u8b8a\u4ee5\u53ca\u8b58\u5225\u6578\u64da\u932f\u8aa4\u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="TDyAAozQcrk3"',id:'"TDyAAozQcrk3"'},"context.show(example_validator.outputs['anomalies'])\n")),(0,r.kt)("h3",{id:"transform"},"Transform"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"Transform")," \u7d44\u4ef6\u70ba\u8a13\u7df4\u548c\u670d\u52d9\u57f7\u884c\u7279\u5fb5\u5de5\u7a0b\u3002")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"Transform")," \u4f7f\u7528",(0,r.kt)("a",{parentName:"p",href:"https://www.tensorflow.org/tfx/transform/get_started"},"TensorFlow Transform")," \u6a21\u7d44\u3002")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"Transform")," \u8f38\u5165\u6578\u64da\u4f86\u81ea ",(0,r.kt)("inlineCode",{parentName:"p"},"ExampleGen")," \u3001 Schema \u4f86\u81ea ",(0,r.kt)("inlineCode",{parentName:"p"},"SchemaGen")," \uff0c\u4ee5\u53ca\u81ea\u884c\u5b9a\u7fa9\u5982\u4f55\u9032\u884c\u7279\u5fb5\u5de5\u7a0b\u7684\u6a21\u7d44\u3002")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\u4ee5\u4e0b\u70ba\u81ea\u884c\u5b9a\u7fa9\u7684 Transform \u7a0b\u5f0f\u78bc\u7bc4\u4f8b\uff0c\uff08\u6709\u95dc TensorFlow Transform API \u7684\u4ecb\u7d39\uff0c",(0,r.kt)("a",{parentName:"p",href:"https://www.tensorflow.org/tfx/tutorials/transform/simple"},"\u8acb\u53c3\u95b1\u6559\u7a0b"),"\uff09\u3002")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Notebook \u9b54\u8853\u6307\u4ee4 ",(0,r.kt)("inlineCode",{parentName:"p"},"%%writefile")," \uff0c\u53ef\u4ee5\u5c07 cell \u5167\u7684\u7a0b\u5f0f\u78bc\u6307\u5b9a\u4fdd\u5b58\u70ba\u6a94\u6848\uff0c\u8a72\u6a94\u6848\u53ef\u4ee5\u7528 ",(0,r.kt)("inlineCode",{parentName:"p"},"Transform")," \u7d44\u4ef6\u5c07\u7a0b\u5f0f\u78bc\u6a94\u6848\u505a\u70ba\u6a21\u7d44\u8f38\u5165\u57f7\u884c\u3002"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="PuNSiUKb4YJf"',id:'"PuNSiUKb4YJf"'},"_taxi_constants_module_file = 'taxi_constants.py'\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="HPjhXuIF4YJh"',id:'"HPjhXuIF4YJh"'},"%%writefile {_taxi_constants_module_file}\n\nNUMERICAL_FEATURES = ['trip_miles', 'fare', 'trip_seconds']\n\nBUCKET_FEATURES = [\n    'pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n    'dropoff_longitude'\n]\n# tf.transform\u7528\u65bc\u7de8\u78bc\u6bcf\u500b\u7279\u5fb5\u7684\u6876\u6578=10\nFEATURE_BUCKET_COUNT = 10\n\nCATEGORICAL_NUMERICAL_FEATURES = [\n    'trip_start_hour', 'trip_start_day', 'trip_start_month',\n    'pickup_census_tract', 'dropoff_census_tract', 'pickup_community_area',\n    'dropoff_community_area'\n]\n\nCATEGORICAL_STRING_FEATURES = [\n    'payment_type',\n    'company',\n]\n\n# tf.transform\u7528\u65bc\u7de8\u78bcVOCAB_FEATURES\u7684\u8a5e\u5f59\u8853\u8a9e\u6578\u91cf=1000\nVOCAB_SIZE = 1000\n\n# Count of out-of-vocab buckets in which unrecognized \n# VOCAB_FEATURES are hashed.\nOOV_SIZE = 10\n\n# Keys\nLABEL_KEY = 'tips'\nFARE_KEY = 'fare'\n\ndef t_name(key):\n  \"\"\"\n  Rename the feature keys so that they don't clash with the raw keys when\n  running the Evaluator component.\n  Args:\n    key: The original feature key\n  Returns:\n    key with '_xf' appended\n  \"\"\"\n  return key + '_xf'\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u63a5\u8457\u7de8\u5beb ",(0,r.kt)("inlineCode",{parentName:"li"},"preprocessing_fn")," \u5c07\u539f\u59cb\u6578\u64da\u8f49\u63db\u7279\u5fb5\u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="4AJ9hBs94YJm"',id:'"4AJ9hBs94YJm"'},"_taxi_transform_module_file = 'taxi_transform.py'\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="MYmxxx9A4YJn"',id:'"MYmxxx9A4YJn"'},'%%writefile {_taxi_transform_module_file}\n\nimport tensorflow as tf\nimport tensorflow_transform as tft\n\n# Imported files such as taxi_constants are normally cached, so changes are\n# not honored after the first import.  Normally this is good for efficiency, but\n# during development when we may be iterating code it can be a problem. To\n# avoid this problem during development, reload the file.\nimport taxi_constants\nimport sys\nif \'google.colab\' in sys.modules:  # Testing to see if we\'re doing development\n  import importlib\n  importlib.reload(taxi_constants)\n\n_NUMERICAL_FEATURES = taxi_constants.NUMERICAL_FEATURES\n_BUCKET_FEATURES = taxi_constants.BUCKET_FEATURES\n_FEATURE_BUCKET_COUNT = taxi_constants.FEATURE_BUCKET_COUNT\n_CATEGORICAL_NUMERICAL_FEATURES = taxi_constants.CATEGORICAL_NUMERICAL_FEATURES\n_CATEGORICAL_STRING_FEATURES = taxi_constants.CATEGORICAL_STRING_FEATURES\n_VOCAB_SIZE = taxi_constants.VOCAB_SIZE\n_OOV_SIZE = taxi_constants.OOV_SIZE\n_FARE_KEY = taxi_constants.FARE_KEY\n_LABEL_KEY = taxi_constants.LABEL_KEY\n\n\ndef _make_one_hot(x, key):\n  """Make a one-hot tensor to encode categorical features.\n  Args:\n    X: A dense tensor\n    key: A string key for the feature in the input\n  Returns:\n    A dense one-hot tensor as a float list\n  """\n  integerized = tft.compute_and_apply_vocabulary(x,\n          top_k=_VOCAB_SIZE,\n          num_oov_buckets=_OOV_SIZE,\n          vocab_filename=key, name=key)\n  depth = (\n      tft.experimental.get_vocabulary_size_by_name(key) + _OOV_SIZE)\n  one_hot_encoded = tf.one_hot(\n      integerized,\n      depth=tf.cast(depth, tf.int32),\n      on_value=1.0,\n      off_value=0.0)\n  return tf.reshape(one_hot_encoded, [-1, depth])\n\n\ndef _fill_in_missing(x):\n  """Replace missing values in a SparseTensor.\n  Fills in missing values of `x` with \'\' or 0, and converts to a dense tensor.\n  Args:\n    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n      in the second dimension.\n  Returns:\n    A rank 1 tensor where missing values of `x` have been filled in.\n  """\n  if not isinstance(x, tf.sparse.SparseTensor):\n    return x\n\n  default_value = \'\' if x.dtype == tf.string else 0\n  return tf.squeeze(\n      tf.sparse.to_dense(\n          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n          default_value),\n      axis=1)\n\n\ndef preprocessing_fn(inputs):\n  """tf.transform\'s callback function for preprocessing inputs.\n  Args:\n    inputs: map from feature keys to raw not-yet-transformed features.\n  Returns:\n    Map from string feature key to transformed feature operations.\n  """\n  outputs = {}\n  for key in _NUMERICAL_FEATURES:\n    # If sparse make it dense, setting nan\'s to 0 or \'\', and apply zscore.\n    outputs[taxi_constants.t_name(key)] = tft.scale_to_z_score(\n        _fill_in_missing(inputs[key]), name=key)\n\n  for key in _BUCKET_FEATURES:\n    outputs[taxi_constants.t_name(key)] = tf.cast(tft.bucketize(\n            _fill_in_missing(inputs[key]), _FEATURE_BUCKET_COUNT, name=key),\n            dtype=tf.float32)\n\n  for key in _CATEGORICAL_STRING_FEATURES:\n    outputs[taxi_constants.t_name(key)] = _make_one_hot(_fill_in_missing(inputs[key]), key)\n\n  for key in _CATEGORICAL_NUMERICAL_FEATURES:\n    outputs[taxi_constants.t_name(key)] = _make_one_hot(tf.strings.strip(\n        tf.strings.as_string(_fill_in_missing(inputs[key]))), key)\n\n  # Was this passenger a big tipper?\n  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])\n  tips = _fill_in_missing(inputs[_LABEL_KEY])\n  outputs[_LABEL_KEY] = tf.where(\n      tf.math.is_nan(taxi_fare),\n      tf.cast(tf.zeros_like(taxi_fare), tf.int64),\n      # Test if the tip was > 20% of the fare.\n      tf.cast(\n          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))\n\n  return outputs\n')),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u5c07\u7279\u5fb5\u5de5\u7a0b\u7a0b\u5f0f\u50b3\u905e\u7d66 ",(0,r.kt)("inlineCode",{parentName:"li"},"Transform")," \u7d44\u4ef6\u8f49\u63db\u8cc7\u6599\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"Transform"),"\u7d44\u4ef6\u5c07\u7522\u751f\u4ee5\u4e0b\u5169\u7a2e\u985e\u578b\u7684\u8f38\u51fa\uff1a",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"transform_graph")," \u662f\u53ef\u4ee5\u57f7\u884c\u9810\u8655\u7406\u64cd\u4f5c\u7684\u5716\uff08\u6b64\u5716\u5c07\u5305\u542b\u5728\u670d\u52d9\u548c\u8a55\u4f30\u6a21\u578b\u4e2d\uff09\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"transformed_examples")," \u8868\u793a\u9810\u8655\u7406\u7684\u8a13\u7df4\u548c\u8a55\u4f30\u6578\u64da\u3002")))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="jHfhth_GiZI9"',id:'"jHfhth_GiZI9"'},"transform = tfx.components.Transform(\n    examples=example_gen.outputs['examples'],\n    schema=schema_gen.outputs['schema'],\n    module_file=os.path.abspath(_taxi_transform_module_file))\ncontext.run(transform, enable_cache=True)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="SClrAaEGR1O5"',id:'"SClrAaEGR1O5"'},"transform.outputs\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u8f38\u51fa\u7684 ",(0,r.kt)("inlineCode",{parentName:"li"},"transform_graph")," \u540c\u6642\u6307\u5411\u5305\u542b3\u500b\u5b50\u76ee\u9304\u7684\u76ee\u9304\u3002",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"transformed_metadata"),"\u5b50\u76ee\u9304\u5305\u542b\u9810\u8655\u7406\u6578\u64da\u7684\u67b6\u69cb\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"transform_fn"),"\u5b50\u76ee\u9304\u5305\u542b\u5be6\u969b\u7684\u9810\u8655\u7406\u5716\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"metadata"),"\u5b50\u76ee\u9304\u5305\u542b\u539f\u59cb\u6578\u64da\u7684\u67b6\u69cb\u3002")))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="5tRw4DneR3i7"',id:'"5tRw4DneR3i7"'},"train_uri = transform.outputs['transform_graph'].get()[0].uri\nos.listdir(train_uri)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="pwbW2zPKR_S4"',id:'"pwbW2zPKR_S4"'},"# Get the URI of the output artifact representing the transformed examples, which is a directory\ntrain_uri = os.path.join(transform.outputs['transformed_examples'].get()[0].uri, 'Split-train')\n\n# Get the list of files in this directory (all compressed TFRecord files)\ntfrecord_filenames = [os.path.join(train_uri, name)\n                      for name in os.listdir(train_uri)]\n\n# Create a `TFRecordDataset` to read these files\ndataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n\n# Iterate over the first 3 records and decode them.\nfor tfrecord in dataset.take(3):\n  serialized_example = tfrecord.numpy()\n  example = tf.train.Example()\n  example.ParseFromString(serialized_example)\n  pp.pprint(example)\n")),(0,r.kt)("h3",{id:"trainer"},"Trainer"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"Trainer"),"\u7d44\u4ef6\u8ca0\u8cac\u8a13\u7df4 TensorFlow \u6a21\u578b\u3002")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"Trainer")," \u9810\u8a2d\u4f7f\u7528 Estimator API \uff0c\u5982\u8981\u4f7f\u7528 Keras API\uff0c\u60a8\u9700\u8981\u901a\u904e\u5728 Trainer \u7684\u69cb\u9020\u51fd\u6578\u4e2d\u8a2d\u7f6e\u4f86\u6307\u5b9a ",(0,r.kt)("inlineCode",{parentName:"p"},"custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor)")," \uff0c\u53c3\u95b1",(0,r.kt)("a",{parentName:"p",href:"https://github.com/tensorflow/community/blob/master/rfcs/20200117-tfx-generic-trainer.md"},"Generic Trainer")," \u3002")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"Trainer")," \u7684\u8f38\u5165\u4f86\u6e90:"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\u4f86\u81ea ",(0,r.kt)("inlineCode",{parentName:"li"},"SchemaGen")," \u7684 Schema\u3002 "),(0,r.kt)("li",{parentName:"ul"},"\u4f86\u81ea ",(0,r.kt)("inlineCode",{parentName:"li"},"Transform")," \u7684 graph\u3002"),(0,r.kt)("li",{parentName:"ul"},"\u8a13\u7df4\u53c3\u6578\u3002"),(0,r.kt)("li",{parentName:"ul"},"\u505a\u70ba\u6a21\u7d44\u8f38\u5165\u7684\u81ea\u5b9a\u7fa9\u7a0b\u5f0f\u78bc\u3002"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\u4ee5\u4e0b\u70ba\u7528\u6236\u81ea\u5b9a\u7fa9\u6a21\u578b\u4ee3\u78bc\u793a\u7bc4\uff08",(0,r.kt)("a",{parentName:"p",href:"https://www.tensorflow.org/guide/keras"},"\u53c3\u898b TensorFlow Keras API \u4ecb\u7d39"),"\uff09\u3002")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\u5275\u7acb ",(0,r.kt)("inlineCode",{parentName:"p"},"taxi_trainer.py")," \u4e4b\u5f8c\u5c07\u7a0b\u5f0f\u78bc\u505a\u70ba\u6a21\u7d44\u50b3\u905e\u7d66 ",(0,r.kt)("inlineCode",{parentName:"p"},"Trainer")," \u7d44\u4ef6\u4e26\u904b\u884c\u5b83\u4f86\u8a13\u7df4\u6a21\u578b\u3002"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="N1376oq04YJt"',id:'"N1376oq04YJt"'},"_taxi_trainer_module_file = 'taxi_trainer.py'\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="nf9UuNng4YJu"',id:'"nf9UuNng4YJu"'},'%%writefile {_taxi_trainer_module_file}\n\nfrom typing import Dict, List, Text\n\nimport os\nimport glob\nfrom absl import logging\n\nimport datetime\nimport tensorflow as tf\nimport tensorflow_transform as tft\n\nfrom tfx import v1 as tfx\nfrom tfx_bsl.public import tfxio\nfrom tensorflow_transform import TFTransformOutput\n\n# Imported files such as taxi_constants are normally cached, so changes are\n# not honored after the first import.  Normally this is good for efficiency, but\n# during development when we may be iterating code it can be a problem. To\n# avoid this problem during development, reload the file.\nimport taxi_constants\nimport sys\nif \'google.colab\' in sys.modules:  # Testing to see if we\'re doing development\n  import importlib\n  importlib.reload(taxi_constants)\n\n_LABEL_KEY = taxi_constants.LABEL_KEY\n\n_BATCH_SIZE = 40\n\n\ndef _input_fn(file_pattern: List[Text],\n              data_accessor: tfx.components.DataAccessor,\n              tf_transform_output: tft.TFTransformOutput,\n              batch_size: int = 200) -> tf.data.Dataset:\n  """Generates features and label for tuning/training.\n\n  Args:\n    file_pattern: List of paths or patterns of input tfrecord files.\n    data_accessor: DataAccessor for converting input to RecordBatch.\n    tf_transform_output: A TFTransformOutput.\n    batch_size: representing the number of consecutive elements of returned\n      dataset to combine in a single batch\n\n  Returns:\n    A dataset that contains (features, indices) tuple where features is a\n      dictionary of Tensors, and indices is a single Tensor of label indices.\n  """\n  return data_accessor.tf_dataset_factory(\n      file_pattern,\n      tfxio.TensorFlowDatasetOptions(\n          batch_size=batch_size, label_key=_LABEL_KEY),\n      tf_transform_output.transformed_metadata.schema)\n\ndef _get_tf_examples_serving_signature(model, tf_transform_output):\n  """Returns a serving signature that accepts `tensorflow.Example`."""\n\n  # We need to track the layers in the model in order to save it.\n  # TODO(b/162357359): Revise once the bug is resolved.\n  model.tft_layer_inference = tf_transform_output.transform_features_layer()\n\n  @tf.function(input_signature=[\n      tf.TensorSpec(shape=[None], dtype=tf.string, name=\'examples\')\n  ])\n  def serve_tf_examples_fn(serialized_tf_example):\n    """Returns the output to be used in the serving signature."""\n    raw_feature_spec = tf_transform_output.raw_feature_spec()\n    # Remove label feature since these will not be present at serving time.\n    raw_feature_spec.pop(_LABEL_KEY)\n    raw_features = tf.io.parse_example(serialized_tf_example, raw_feature_spec)\n    transformed_features = model.tft_layer_inference(raw_features)\n    logging.info(\'serve_transformed_features = %s\', transformed_features)\n\n    outputs = model(transformed_features)\n    # TODO(b/154085620): Convert the predicted labels from the model using a\n    # reverse-lookup (opposite of transform.py).\n    return {\'outputs\': outputs}\n\n  return serve_tf_examples_fn\n\n\ndef _get_transform_features_signature(model, tf_transform_output):\n  """Returns a serving signature that applies tf.Transform to features."""\n\n  # We need to track the layers in the model in order to save it.\n  # TODO(b/162357359): Revise once the bug is resolved.\n  model.tft_layer_eval = tf_transform_output.transform_features_layer()\n\n  @tf.function(input_signature=[\n      tf.TensorSpec(shape=[None], dtype=tf.string, name=\'examples\')\n  ])\n  def transform_features_fn(serialized_tf_example):\n    """Returns the transformed_features to be fed as input to evaluator."""\n    raw_feature_spec = tf_transform_output.raw_feature_spec()\n    raw_features = tf.io.parse_example(serialized_tf_example, raw_feature_spec)\n    transformed_features = model.tft_layer_eval(raw_features)\n    logging.info(\'eval_transformed_features = %s\', transformed_features)\n    return transformed_features\n\n  return transform_features_fn\n\n\ndef export_serving_model(tf_transform_output, model, output_dir):\n  """Exports a keras model for serving.\n  Args:\n    tf_transform_output: Wrapper around output of tf.Transform.\n    model: A keras model to export for serving.\n    output_dir: A directory where the model will be exported to.\n  """\n  # The layer has to be saved to the model for keras tracking purpases.\n  model.tft_layer = tf_transform_output.transform_features_layer()\n\n  signatures = {\n      \'serving_default\':\n          _get_tf_examples_serving_signature(model, tf_transform_output),\n      \'transform_features\':\n          _get_transform_features_signature(model, tf_transform_output),\n  }\n\n  model.save(output_dir, save_format=\'tf\', signatures=signatures)\n\n\ndef _build_keras_model(tf_transform_output: TFTransformOutput\n                       ) -> tf.keras.Model:\n  """Creates a DNN Keras model for classifying taxi data.\n\n  Args:\n    tf_transform_output: [TFTransformOutput], the outputs from Transform\n\n  Returns:\n    A keras Model.\n  """\n  feature_spec = tf_transform_output.transformed_feature_spec().copy()\n  feature_spec.pop(_LABEL_KEY)\n\n  inputs = {}\n  for key, spec in feature_spec.items():\n    if isinstance(spec, tf.io.VarLenFeature):\n      inputs[key] = tf.keras.layers.Input(\n          shape=[None], name=key, dtype=spec.dtype, sparse=True)\n    elif isinstance(spec, tf.io.FixedLenFeature):\n      # TODO(b/208879020): Move into schema such that spec.shape is [1] and not\n      # [] for scalars.\n      inputs[key] = tf.keras.layers.Input(\n          shape=spec.shape or [1], name=key, dtype=spec.dtype)\n    else:\n      raise ValueError(\'Spec type is not supported: \', key, spec)\n  \n  output = tf.keras.layers.Concatenate()(tf.nest.flatten(inputs))\n  output = tf.keras.layers.Dense(100, activation=\'relu\')(output)\n  output = tf.keras.layers.Dense(70, activation=\'relu\')(output)\n  output = tf.keras.layers.Dense(50, activation=\'relu\')(output)\n  output = tf.keras.layers.Dense(20, activation=\'relu\')(output)\n  output = tf.keras.layers.Dense(1)(output)\n  return tf.keras.Model(inputs=inputs, outputs=output)\n\n\n# TFX Trainer will call this function.\ndef run_fn(fn_args: tfx.components.FnArgs):\n  """Train the model based on given args.\n\n  Args:\n    fn_args: Holds args used to train the model as name/value pairs.\n  """\n  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n\n  train_dataset = _input_fn(fn_args.train_files, fn_args.data_accessor, \n                            tf_transform_output, _BATCH_SIZE)\n  eval_dataset = _input_fn(fn_args.eval_files, fn_args.data_accessor, \n                           tf_transform_output, _BATCH_SIZE)\n\n  model = _build_keras_model(tf_transform_output)\n\n  model.compile(\n      loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n      optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n      metrics=[tf.keras.metrics.BinaryAccuracy()])\n\n  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n      log_dir=fn_args.model_run_dir, update_freq=\'batch\')\n\n  model.fit(\n      train_dataset,\n      steps_per_epoch=fn_args.train_steps,\n      validation_data=eval_dataset,\n      validation_steps=fn_args.eval_steps,\n      callbacks=[tensorboard_callback])\n\n  # Export the model.\n  export_serving_model(tf_transform_output, model, fn_args.serving_model_dir)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="429-vvCWibO0"',id:'"429-vvCWibO0"'},"trainer = tfx.components.Trainer(\n    module_file=os.path.abspath(_taxi_trainer_module_file),\n    examples=transform.outputs['transformed_examples'],\n    transform_graph=transform.outputs['transform_graph'],\n    schema=schema_gen.outputs['schema'],\n    train_args=tfx.proto.TrainArgs(num_steps=10000),\n    eval_args=tfx.proto.EvalArgs(num_steps=5000))\ncontext.run(trainer, enable_cache=True)\n")),(0,r.kt)("h3",{id:"\u4f7f\u7528-tensorboard-\u5206\u6790\u8a13\u7df4"},"\u4f7f\u7528 TensorBoard \u5206\u6790\u8a13\u7df4"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u6aa2\u8996 'Format-Serving' \u76ee\u9304\u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="bXe62WE0S0Ek"',id:'"bXe62WE0S0Ek"'},"model_artifact_dir = trainer.outputs['model'].get()[0].uri\npp.pprint(os.listdir(model_artifact_dir))\nmodel_dir = os.path.join(model_artifact_dir, 'Format-Serving')\npp.pprint(os.listdir(model_dir))\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u53ef\u4ee5\u900f\u904e TensorBoard \u5206\u6790\u6a21\u578b\u8a13\u7df4\u66f2\u7dda\u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="-APzqz2NeAyj"',id:'"-APzqz2NeAyj"'},"model_run_artifact_dir = trainer.outputs['model_run'].get()[0].uri\n\n%load_ext tensorboard\n%tensorboard --logdir {model_run_artifact_dir}\n")),(0,r.kt)("h3",{id:"evaluator"},"Evaluator"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"Evaluator")," \u7d44\u4ef6\u53ef\u8a55\u4f30\u6a21\u578b\u6027\u80fd\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"Evaluator")," \u7d44\u4ef6\u70ba ",(0,r.kt)("a",{parentName:"li",href:"https://www.tensorflow.org/tfx/model_analysis/get_started"},"TensorFlow Model Analysis (TFMA)")," \u6a21\u7d44\u529f\u80fd\u3002 "),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"Evaluator")," \u53ef\u4ee5\u8a2d\u5b9a\u9580\u6abb\u503c\u4ee5\u6bd4\u8f03\u4e26\u9078\u64c7\u8f03\u4f73\u7684\u6a21\u578b\u3002\u9019\u5728\u751f\u7522\u7ba1\u9053\u8a2d\u7f6e\u4e2d\u5f88\u6709\u7528\uff0c\u60a8\u53ef\u4ee5\u6bcf\u5929\u81ea\u52d5\u8a13\u7df4\u548c\u9a57\u8b49\u6a21\u578b\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"Evaluator")," \u7684\u8f38\u5165:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\u8f38\u5165\u8cc7\u6599\u96c6\u4f86\u81ea ",(0,r.kt)("inlineCode",{parentName:"li"},"ExampleGen"),"\u3002"),(0,r.kt)("li",{parentName:"ul"},"\u8a13\u7df4\u6a21\u578b\u4f86\u81ea ",(0,r.kt)("inlineCode",{parentName:"li"},"Trainer")," \u548c\u5207\u7247\u914d\u7f6e\u3002\u5207\u7247\u914d\u7f6e\u5141\u8a31\u60a8\u6839\u64da\u7279\u5fb5\u503c\u5c0d\u6307\u6a19\u9032\u884c\u5207\u7247\uff08\u4f8b\u5982\uff0c\u60a8\u7684\u6a21\u578b\u5728\u65e9\u4e0a 8 \u9ede\u548c\u665a\u4e0a 8 \u9ede\u958b\u59cb\u7684\u51fa\u79df\u8eca\u884c\u7a0b\u4e2d\u8868\u73fe\u5982\u4f55\uff1f\uff09\u3002"))),(0,r.kt)("li",{parentName:"ul"},"\u5728\u6b64\u7b46\u8a18\u672c\u7bc4\u4f8b\u53ea\u8a13\u7df4\u4e00\u500b\u6a21\u578b\uff0c\u6240\u4ee5",(0,r.kt)("inlineCode",{parentName:"li"},"Evaluator"),"\u81ea\u52d5\u5c07\u6a21\u578b\u6a19\u8a18\u70ba\u201cGood\u201d\u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="fVhfzzh9PDEx"',id:'"fVhfzzh9PDEx"'},"# Imported files such as taxi_constants are normally cached, so changes are\n# not honored after the first import.  Normally this is good for efficiency, but\n# during development when we may be iterating code it can be a problem. To\n# avoid this problem during development, reload the file.\nimport taxi_constants\nimport sys\nif 'google.colab' in sys.modules:  # Testing to see if we're doing development\n  import importlib\n  importlib.reload(taxi_constants)\n\neval_config = tfma.EvalConfig(\n    model_specs=[\n        # This assumes a serving model with signature 'serving_default'. If\n        # using estimator based EvalSavedModel, add signature_name: 'eval' and\n        # remove the label_key.\n        tfma.ModelSpec(\n            signature_name='serving_default',\n            label_key=taxi_constants.LABEL_KEY,\n            preprocessing_function_names=['transform_features'],\n            )\n        ],\n    metrics_specs=[\n        tfma.MetricsSpec(\n            # The metrics added here are in addition to those saved with the\n            # model (assuming either a keras model or EvalSavedModel is used).\n            # Any metrics added into the saved model (for example using\n            # model.compile(..., metrics=[...]), etc) will be computed\n            # automatically.\n            # To add validation thresholds for metrics saved with the model,\n            # add them keyed by metric name to the thresholds map.\n            metrics=[\n                tfma.MetricConfig(class_name='ExampleCount'),\n                tfma.MetricConfig(class_name='BinaryAccuracy',\n                  threshold=tfma.MetricThreshold(\n                      value_threshold=tfma.GenericValueThreshold(\n                          lower_bound={'value': 0.5}),\n                      # Change threshold will be ignored if there is no\n                      # baseline model resolved from MLMD (first run).\n                      change_threshold=tfma.GenericChangeThreshold(\n                          direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                          absolute={'value': -1e-10})))\n            ]\n        )\n    ],\n    slicing_specs=[\n        # An empty slice spec means the overall slice, i.e. the whole dataset.\n        tfma.SlicingSpec(),\n        # Data can be sliced along a feature column. In this case, data is\n        # sliced along feature column trip_start_hour.\n        tfma.SlicingSpec(\n            feature_keys=['trip_start_hour'])\n    ])\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="Zjcx8g6mihSt"',id:'"Zjcx8g6mihSt"'},"# Use TFMA to compute a evaluation statistics over features of a model and\n# validate them against a baseline.\n\n# The model resolver is only required if performing model validation in addition\n# to evaluation. In this case we validate against the latest blessed model. If\n# no model has been blessed before (as in this case) the evaluator will make our\n# candidate the first blessed model.\nmodel_resolver = tfx.dsl.Resolver(\n      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n      model_blessing=tfx.dsl.Channel(\n          type=tfx.types.standard_artifacts.ModelBlessing)).with_id(\n              'latest_blessed_model_resolver')\ncontext.run(model_resolver, enable_cache=True)\n\nevaluator = tfx.components.Evaluator(\n    examples=example_gen.outputs['examples'],\n    model=trainer.outputs['model'],\n    baseline_model=model_resolver.outputs['model'],\n    eval_config=eval_config)\ncontext.run(evaluator, enable_cache=True)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="k4GghePOTJxL"',id:'"k4GghePOTJxL"'},"evaluator.outputs\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="U729j5X5QQUQ"',id:'"U729j5X5QQUQ"'},"context.show(evaluator.outputs['evaluation'])\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u8981\u5207\u7247\u986f\u793a\u6a21\u578b\u60c5\u5f62\uff0c\u9700\u4f7f\u7528 TFMA \u6a21\u7d44\u3002"),(0,r.kt)("li",{parentName:"ul"},"\u5728\u6b64\u793a\u7bc4\u5c07",(0,r.kt)("inlineCode",{parentName:"li"},"trip_start_hour"),"\u5207\u7247\u8996\u89ba\u5316\uff0cTFMA \u652f\u63f4\u8a31\u591a\u5176\u4ed6\u53ef\u8996\u5316\uff0c\u4f8b\u5982\u516c\u5e73\u6307\u6a19\u548c\u7e6a\u88fd\u6a21\u578b\u6027\u80fd\u7684\u6642\u9593\u5e8f\u5217\u3002\u8981\u4e86\u89e3\u66f4\u591a\u4fe1\u606f\uff0c\u8acb\u53c3\u95b1",(0,r.kt)("a",{parentName:"li",href:"https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic"},"\u6559\u5b78"),"\u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="pyis6iy0HLdi"',id:'"pyis6iy0HLdi"'},"import tensorflow_model_analysis as tfma\n\n# Get the TFMA output result path and load the result.\nPATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\ntfma_result = tfma.load_eval_result(PATH_TO_RESULT)\n\n# Show data sliced along feature column trip_start_hour.\ntfma.view.render_slicing_metrics(\n    tfma_result, slicing_column='trip_start_hour')\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u901a\u904e\u9580\u6abb\u503c\u7684\u6a21\u578b\u6703\u5f97\u5230\u795d\u798f ",(0,r.kt)("inlineCode",{parentName:"li"},"blessing")," \uff0c\u7b2c\u4e00\u6b21\u9810\u8a2d\u6703\u81ea\u52d5\u53d6\u5f97\uff0c\u4e4b\u5f8c\u6301\u7e8c\u8a13\u7df4\u904e\u7a0b\u6703\u5c07\u53d6\u5f97\u795d\u798f\u7684\u6a21\u578b\u518d\u4e0a\u7dda\u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="FZmiRtg6TKtR"',id:'"FZmiRtg6TKtR"'},"blessing_uri = evaluator.outputs['blessing'].get()[0].uri\n!ls -l {blessing_uri}\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u73fe\u5728\u4e5f\u53ef\u4ee5\u8b80\u53d6\u7d93\u904e\u9a57\u8b49\u6210\u529f\u7684\u7d00\u9304\u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="lxa5G08bSJ8a"',id:'"lxa5G08bSJ8a"'},"PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\nprint(tfma.load_validation_result(PATH_TO_RESULT))\n")),(0,r.kt)("h3",{id:"pusher"},"Pusher"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"Pusher")," \u7d44\u4ef6\u901a\u5e38\u4f4d\u65bc TFX \u7ba1\u9053\u672b\u7aef\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"Pusher")," \u7d44\u4ef6\u6aa2\u67e5\u6a21\u578b\u662f\u5426\u5df2\u901a\u904e\u9a57\u8b49\uff0c\u5982\u679c\u662f\uff0c\u5247\u5c07\u6a21\u578b\u5c0e\u51fa\u81f3\n",(0,r.kt)("inlineCode",{parentName:"li"},"_serving_model_dir"),"\u3002"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"Pusher")," \u5c07\u4ee5 ",(0,r.kt)("inlineCode",{parentName:"li"},"SavedModel")," \u683c\u5f0f\u5c0e\u51fa\u60a8\u7684\u6a21\u578b\u3002")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="r45nQ69eikc9"',id:'"r45nQ69eikc9"'},"pusher = tfx.components.Pusher(\n    model=trainer.outputs['model'],\n    model_blessing=evaluator.outputs['blessing'],\n    push_destination=tfx.proto.PushDestination(\n        filesystem=tfx.proto.PushDestination.Filesystem(\n            base_directory=_serving_model_dir)))\ncontext.run(pusher, enable_cache=True)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="pRkWo-MzTSss"',id:'"pRkWo-MzTSss"'},"pusher.outputs\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'id="4zyIqWl9TSdG"',id:'"4zyIqWl9TSdG"'},"push_uri = pusher.outputs['pushed_model'].get()[0].uri\nmodel = tf.saved_model.load(push_uri)\n\nfor item in model.signatures.items():\n  pp.pprint(item)\n")),(0,r.kt)("p",null,"\u7d42\u65bc\u5b8c\u6210 TFX \u6240\u6709\u7d44\u4ef6\u7684\u793a\u7bc4!"))}d.isMDXComponent=!0}}]);